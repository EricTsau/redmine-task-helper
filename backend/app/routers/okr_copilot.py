"""
OKR Copilot è·¯ç”±
æä¾›ç­–ç•¥å ±å‘Šç”Ÿæˆèˆ‡å¤šæ ¼å¼è¼¸å‡ºåŠŸèƒ½
"""
from fastapi import APIRouter, Depends, HTTPException
from fastapi.responses import FileResponse
from sqlmodel import Session, select
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
import json
import os
import subprocess
import tempfile
import shutil

from app.database import get_session
from app.dependencies import get_current_user, get_redmine_service, get_openai_service
from app.models import User, UserSettings, AIWorkSummarySettings, GitLabInstance, GitLabWatchlist
from app.services.redmine_client import RedmineService
from app.services.openai_service import OpenAIService
from app.services.gitlab_service import GitLabService

router = APIRouter(tags=["okr-copilot"])


# ============ Request/Response Models ============

class PreviewRequest(BaseModel):
    start_date: str  # YYYY-MM-DD
    end_date: str    # YYYY-MM-DD


class ImageInfo(BaseModel):
    url: str
    caption: Optional[str] = None
    issue_id: Optional[int] = None


class DataPreviewResponse(BaseModel):
    completed_issues: int
    in_progress_issues: int  # æ–°å¢ï¼šé€²è¡Œä¸­çš„ issues
    gitlab_commits: int
    gitlab_releases: int
    available_images: List[ImageInfo]


class GenerateRequest(BaseModel):
    start_date: str  # YYYY-MM-DD
    end_date: str    # YYYY-MM-DD
    format: str      # "pptx", "pdf", "docx", "md"
    selected_images: List[str] = []


class GenerateResponse(BaseModel):
    download_url: Optional[str] = None
    markdown: Optional[str] = None
    ai_analysis: Optional[Dict[str, Any]] = None  # AI åˆ†æçµæœ


# ============ Helper Functions ============

def get_gitlab_instances(session: Session, user: User) -> List[GitLabInstance]:
    """å–å¾—ä½¿ç”¨è€…çš„ GitLab å¯¦ä¾‹"""
    return session.exec(
        select(GitLabInstance).where(GitLabInstance.owner_id == user.id)
    ).all()


def get_gitlab_watchlist(session: Session, user: User) -> List[GitLabWatchlist]:
    """å–å¾—ä½¿ç”¨è€…çš„ GitLab é—œæ³¨å°ˆæ¡ˆ"""
    return session.exec(
        select(GitLabWatchlist)
        .where(GitLabWatchlist.owner_id == user.id)
        .where(GitLabWatchlist.is_included == True)
    ).all()


async def fetch_gitlab_data(
    session: Session, 
    user: User, 
    start_date: datetime, 
    end_date: datetime
) -> Dict[str, Any]:
    """å–å¾— GitLab è³‡æ–™"""
    instances = get_gitlab_instances(session, user)
    watchlist = get_gitlab_watchlist(session, user)
    
    total_commits = 0
    total_releases = 0
    
    for instance in instances:
        service = GitLabService(instance)
        
        # å–å¾—æ­¤å¯¦ä¾‹çš„é—œæ³¨å°ˆæ¡ˆ
        instance_projects = [w for w in watchlist if w.instance_id == instance.id]
        
        for project in instance_projects:
            try:
                # ä½¿ç”¨ gitlab_project_id è€Œé project_id
                commits = await service.get_commits(
                    project.gitlab_project_id, 
                    start_date, 
                    end_date
                )
                total_commits += len(commits)
                
                # GitLab releases é€šå¸¸éœ€è¦å¦å¤–çš„ API å‘¼å«
                # é€™è£¡ç°¡åŒ–è™•ç†ï¼Œä½¿ç”¨ tags æˆ– releases endpoint
            except Exception as e:
                print(f"Error fetching GitLab data for project {project.gitlab_project_id}: {e}")
    
    return {
        "commits": total_commits,
        "releases": total_releases
    }


async def fetch_redmine_data(
    redmine: RedmineService,
    session: Session,
    user: User,
    start_date: str,
    end_date: str
) -> Dict[str, Any]:
    """å–å¾— Redmine è³‡æ–™ (å·²å®Œæˆ + é€²è¡Œä¸­)"""
    # å–å¾— AI Summary è¨­å®šä¸­çš„å°ˆæ¡ˆå’Œäººå“¡
    settings = session.exec(
        select(AIWorkSummarySettings).where(AIWorkSummarySettings.owner_id == user.id)
    ).first()
    
    project_ids = []
    user_ids = []
    
    if settings:
        try:
            project_ids = json.loads(settings.target_project_ids)
            user_ids = json.loads(settings.target_user_ids)
        except:
            pass
    
    completed_issues = 0
    in_progress_issues = 0
    images = []
    issue_list = []
    
    # Get Redmine URL from settings for relative image resolution
    user_settings = session.exec(
        select(UserSettings).where(UserSettings.user_id == user.id)
    ).first()
    redmine_url = user_settings.redmine_url.rstrip('/') if user_settings and user_settings.redmine_url else ""

    for project_id in project_ids:
        try:
            # 1. å–å¾—å°ˆæ¡ˆåœ¨æ™‚é–“å€é–“å…§é—œé–‰çš„ issues
            closed_issues = redmine.search_issues_advanced(
                project_id=project_id,
                status="closed",
                updated_after=start_date,
                updated_before=end_date,
                include=["journals", "attachments"],
                limit=100
            )
            completed_issues += len(closed_issues)
            issue_list.extend(closed_issues)
            
            # 2. å–å¾—å°ˆæ¡ˆåœ¨æ™‚é–“å€é–“å…§æ›´æ–°éçš„é€²è¡Œä¸­ issues
            open_issues = redmine.search_issues_advanced(
                project_id=project_id,
                status="open",
                updated_after=start_date,
                updated_before=end_date,
                include=["journals", "attachments"],
                limit=100
            )
            in_progress_issues += len(open_issues)
            issue_list.extend(open_issues)
            
        except Exception as e:
            print(f"Error fetching Redmine issues for project {project_id}: {e}")
    
    # å¾ issues çš„ notes ä¸­æå–åœ–ç‰‡
    import re
    for issue in issue_list:
        try:
            # Redmine issue æ˜¯ç‰©ä»¶ï¼Œä½¿ç”¨ .id å±¬æ€§
            issue_id = getattr(issue, 'id', 0) if hasattr(issue, 'id') else issue.get('id', 0) if isinstance(issue, dict) else 0
            if not issue_id:
                continue
            
            # å»ºç«‹ issue attachments å°ç…§è¡¨ (filename -> content_url)
            attachments_map = {}
            if hasattr(issue, 'attachments'):
                for attachment in issue.attachments:
                    filename = getattr(attachment, 'filename', '')
                    content_url = getattr(attachment, 'content_url', '')
                    if filename and content_url:
                        attachments_map[filename] = content_url
            
            # ç›´æ¥ä½¿ç”¨ issue.journals (å› å·²é€é include è¼‰å…¥) æˆ–æ˜¯å¦‚æœ unavailable å‰‡ fallback
            journals = getattr(issue, 'journals', [])
            # è‹¥ issue ç‰©ä»¶ä¸­ç„¡ journalsï¼Œå˜—è©¦é‡æ–°ç²å– (Backward Compatibility)
            if not journals: 
                try:
                    journals = redmine.get_issue_journals(issue_id)
                except:
                    pass

            for journal in journals:
                notes = journal.get("notes", "") if isinstance(journal, dict) else getattr(journal, 'notes', '')
                if notes:
                    # æå– Markdown åœ–ç‰‡èªæ³•å’Œ HTML img æ¨™ç±¤
                    img_pattern = r'!\[([^\]]*)\]\(([^)]+)\)|<img[^>]+src=["\']([^"\']+)["\']'
                    matches = re.findall(img_pattern, notes)
                    for match in matches:
                        url = match[1] or match[2]
                        if url:
                            # URL Resolution Logic
                            if not url.startswith(('http://', 'https://')):
                                # 1. Try finding in attachments (Redmine often references by filename)
                                if url in attachments_map:
                                    url = attachments_map[url]
                                # 2. If valid Redmine URL exists, treat as relative path
                                elif redmine_url:
                                    clean_url = url.lstrip('/')
                                    url = f"{redmine_url}/{clean_url}"
                            
                            images.append({
                                "url": url,
                                "caption": match[0] or f"Issue #{issue_id}",
                                "issue_id": issue_id
                            })
        except Exception as e:
            print(f"Error extracting images from issue: {e}")
    
    return {
        "completed_issues": completed_issues,
        "in_progress_issues": in_progress_issues,
        "images": images
    }


# ============ AI åˆ†æå‡½æ•¸ ============

async def analyze_kr_status(
    openai: OpenAIService,
    completed_issues: int,
    gitlab_commits: int,
    gitlab_releases: int,
    start_date: str,
    end_date: str
) -> Dict[str, Any]:
    """
    4.1 AI ç´…ç¶ ç‡ˆåˆ¤æ–· - åˆ†æ KR ç‹€æ…‹
    è¿”å›: {"status": "green"/"yellow"/"red", "reason": "èªªæ˜"}
    """
    prompt = f"""ä½ æ˜¯ä¸€å€‹ OKR åˆ†æå°ˆå®¶ã€‚è«‹æ ¹æ“šä»¥ä¸‹æ•¸æ“šè©•ä¼°åœ˜éšŠçš„é€²åº¦ç‹€æ…‹ã€‚

å ±å‘Šå€é–“: {start_date} ~ {end_date}
å·²å®Œæˆ Issues: {completed_issues}
GitLab Commits: {gitlab_commits}
GitLab Releases: {gitlab_releases}

è«‹ç”¨ JSON æ ¼å¼å›è¦†ï¼ŒåŒ…å«:
- status: "green"(é€²åº¦è‰¯å¥½)ã€"yellow"(éœ€æ³¨æ„)ã€"red"(é€²åº¦è½å¾Œ)
- reason: ç°¡çŸ­èªªæ˜åˆ¤æ–·ç†ç”± (ä¸­æ–‡ï¼Œ50å­—å…§)
- suggestions: æ”¹å–„å»ºè­°é™£åˆ— (ä¸­æ–‡ï¼Œæœ€å¤š3æ¢)

åªè¼¸å‡º JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚
"""
    
    try:
        response = await openai.chat_completion([
            {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹ OKR åˆ†æå°ˆå®¶ï¼Œè«‹ç”¨ JSON æ ¼å¼å›è¦†ã€‚"},
            {"role": "user", "content": prompt}
        ], temperature=0.3)
        
        # è§£æ JSON
        import re
        json_match = re.search(r'\{[\s\S]*\}', response)
        if json_match:
            return json.loads(json_match.group())
    except Exception as e:
        print(f"KR status analysis error: {e}")
    
    # é è¨­å›å‚³
    return {"status": "yellow", "reason": "ç„¡æ³•åˆ†æ", "suggestions": []}


async def generate_code_contribution_summary(
    openai: OpenAIService,
    gitlab_commits: int,
    gitlab_releases: int,
    start_date: str,
    end_date: str
) -> str:
    """
    4.2 ä»£ç¢¼è²¢ç»æ‘˜è¦ - Release Impact åˆ†æ
    """
    if gitlab_commits == 0 and gitlab_releases == 0:
        return "æœ¬æœŸé–“ç„¡ä»£ç¢¼è®Šæ›´æ´»å‹•ã€‚"
    
    prompt = f"""è«‹æ ¹æ“šä»¥ä¸‹ GitLab æ´»å‹•æ•¸æ“šï¼Œæ’°å¯«ä¸€æ®µç°¡æ½”çš„ä»£ç¢¼è²¢ç»æ‘˜è¦ï¼Œèªªæ˜é€™äº›è®Šæ›´å°æ¥­å‹™çš„å½±éŸ¿ã€‚

å ±å‘Šå€é–“: {start_date} ~ {end_date}
GitLab Commits: {gitlab_commits}
GitLab Releases: {gitlab_releases}

è«‹ç”¨ 2-3 å¥è©±ç¸½çµï¼Œç”¨ä¸­æ–‡å›ç­”ï¼Œé‡é»åœ¨æ–¼æ¥­å‹™åƒ¹å€¼å’ŒæŠ€è¡“æˆæœã€‚
"""
    
    try:
        response = await openai.chat_completion([
            {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹æŠ€è¡“ç¸½ç›£ï¼Œæ“…é•·å°‡æŠ€è¡“å·¥ä½œè½‰åŒ–ç‚ºæ¥­å‹™åƒ¹å€¼èªªæ˜ã€‚"},
            {"role": "user", "content": prompt}
        ], temperature=0.5)
        return response.strip()
    except Exception as e:
        print(f"Code contribution summary error: {e}")
    
    return f"æœ¬æœŸé–“å…±æœ‰ {gitlab_commits} æ¬¡æäº¤å’Œ {gitlab_releases} å€‹ç‰ˆæœ¬ç™¼å¸ƒã€‚"


async def generate_next_steps(
    openai: OpenAIService,
    completed_issues: int,
    gitlab_commits: int,
    kr_status: Dict[str, Any]
) -> List[str]:
    """
    4.3 ä¸‹é€±è¨ˆç•«è‡ªå‹•è£œå®Œ - Next Step Generation
    """
    status_text = {
        "green": "é€²åº¦è‰¯å¥½",
        "yellow": "éœ€è¦æ³¨æ„",
        "red": "é€²åº¦è½å¾Œ"
    }.get(kr_status.get("status", "yellow"), "æœªçŸ¥")
    
    prompt = f"""æ ¹æ“šä»¥ä¸‹åœ˜éšŠç‹€æ…‹ï¼Œè«‹å»ºè­° 3-5 æ¢ä¸‹é€±çš„å·¥ä½œè¨ˆç•«ã€‚

ç•¶å‰ç‹€æ…‹: {status_text}
å·²å®Œæˆ Issues: {completed_issues}æœ¬æœŸé–“ Commits: {gitlab_commits}
åˆ†æç†ç”±: {kr_status.get('reason', '')}

è«‹ç”¨ JSON é™£åˆ—æ ¼å¼å›è¦†ï¼Œæ¯æ¢å»ºè­°æ˜¯ä¸€å€‹å­—ä¸²ï¼Œç”¨ä¸­æ–‡ã€‚
åªè¼¸å‡º JSON é™£åˆ—ï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚
"""
    
    try:
        response = await openai.chat_completion([
            {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹å°ˆæ¡ˆç¶“ç†ï¼Œè«‹ç”¨ JSON é™£åˆ—æ ¼å¼å›è¦†å·¥ä½œå»ºè­°ã€‚"},
            {"role": "user", "content": prompt}
        ], temperature=0.6)
        
        # è§£æ JSON é™£åˆ—
        import re
        json_match = re.search(r'\[[\s\S]*\]', response)
        if json_match:
            return json.loads(json_match.group())
    except Exception as e:
        print(f"Next steps generation error: {e}")
    
    # é è¨­å›å‚³
    return ["ç¹¼çºŒæ¸…é™¤å¾…è™•ç†çš„ Issues", "é‡å°é—œéµåŠŸèƒ½é€²è¡Œæ¸¬è©¦", "æº–å‚™ä¸‹ä¸€æ¬¡ç™¼å¸ƒ"]


def generate_marp_markdown(
    start_date: str,
    end_date: str,
    completed_issues: int,
    gitlab_commits: int,
    gitlab_releases: int,
    selected_images: List[str],
    kr_status: Optional[Dict[str, Any]] = None,
    code_summary: Optional[str] = None,
    next_steps: Optional[List[str]] = None,
    completed_issue_list: Optional[List[Dict[str, Any]]] = None
) -> str:
    """ç”Ÿæˆ Marp æ ¼å¼çš„ Markdown (å« AI åˆ†æ)"""
    
    # ç‹€æ…‹åœ–ç¤º
    status_icons = {
        "green": "ğŸŸ¢",
        "yellow": "ğŸŸ¡", 
        "red": "ğŸ”´"
    }
    status = kr_status.get("status", "yellow") if kr_status else "yellow"
    status_icon = status_icons.get(status, "ğŸŸ¡")
    status_text = {
        "green": "é€²åº¦è‰¯å¥½",
        "yellow": "éœ€è¦æ³¨æ„",
        "red": "é€²åº¦è½å¾Œ"
    }.get(status, "éœ€è¦æ³¨æ„")
    
    slides = [
        f"""---
marp: true
theme: uncover
class: invert
paginate: true
---

# OKR æˆæœåŒ¯å ±
### å ±å‘Šå€é–“: {start_date} ~ {end_date}

---

## ğŸ“Š æˆæœæ‘˜è¦

| æŒ‡æ¨™ | æ•¸é‡ |
|------|------|
| å·²å®Œæˆ Issues | {completed_issues} |
| GitLab Commits | {gitlab_commits} |
| GitLab Releases | {gitlab_releases} |

"""
    ]

    # æ·»åŠ è©³ç´°å·¥ä½œåˆ—è¡¨ (å¦‚æœæœ‰)
    if completed_issue_list:
        # å–å‰ 10 ç­†æˆ–æ ¹æ“šéœ€æ±‚èª¿æ•´
        top_issues = completed_issue_list[:10]
        
        # å»ºæ§‹è¡¨æ ¼ rows
        table_rows = []
        for issue in top_issues:
            subject = issue.get('subject', 'N/A')
            # æˆªæ–·éé•·æ¨™é¡Œ
            if len(subject) > 30:
                subject = subject[:28] + "..."
            
            status_name = issue.get('status', {}).get('name', 'Done') if isinstance(issue.get('status'), dict) else issue.get('status', 'Done')
            
            # å˜—è©¦å–å¾—æè¿°æˆ–æœ€å¾Œç­†è¨˜ä½œç‚ºç°¡è¿° (é€™è£¡å‡è¨­ issue çµæ§‹å¯èƒ½æœ‰ description æˆ– notes)
            # ç‚ºäº†ç°¡åŒ–ï¼Œæˆ‘å€‘å…ˆåªé¡¯ç¤ºæ¨™é¡Œå’Œç‹€æ…‹
            table_rows.append(f"| {status_name} | {subject} |")

        rows_md = "\n".join(table_rows)
        
        slides.append(f"""---

## âœ… å·²å®Œæˆå·¥ä½œè©³æƒ… (Top 10)

| ç‹€æ…‹ | ä¸»é¡Œ |
|------|------|
{rows_md}

""")

    slides.append(f"""---

## {status_icon} é€²åº¦ç‹€æ…‹: {status_text}

{kr_status.get('reason', '') if kr_status else ''}

""")
    
    # æ·»åŠ å»ºè­°é é¢
    if kr_status and kr_status.get('suggestions'):
        suggestions_text = "\n".join([f"- {s}" for s in kr_status['suggestions'][:3]])
        slides.append(f"""---

## ğŸ’¡ æ”¹å–„å»ºè­°

{suggestions_text}

""")
    
    # æ·»åŠ ä»£ç¢¼è²¢ç»æ‘˜è¦
    if code_summary:
        slides.append(f"""---

## ğŸš€ æŠ€è¡“æˆæœ

{code_summary}

""")
    
    # æ·»åŠ ä¸‹é€±è¨ˆç•«
    if next_steps:
        steps_text = "\n".join([f"- {s}" for s in next_steps[:5]])
        slides.append(f"""---

## ğŸ“‹ ä¸‹é€±è¨ˆç•«

{steps_text}

""")
    
    # æ·»åŠ é¸ä¸­çš„åœ–ç‰‡ä½œç‚ºè­‰æ“šé 
    for i, img_url in enumerate(selected_images[:5]):  # æœ€å¤š 5 å¼µåœ–ç‰‡
        slides.append(f"""---

## ğŸ–¼ï¸ æˆæœå±•ç¤º {i + 1}

![width:800px]({img_url})

""")
    
    slides.append("""---

# è¬è¬è§€çœ‹

*ç”± OKR Copilot è‡ªå‹•ç”Ÿæˆ*
""")
    
    return "\n".join(slides)


# ============ API Endpoints ============

@router.post("/api/okr-copilot/preview", response_model=DataPreviewResponse)
async def preview_data(
    request: PreviewRequest,
    session: Session = Depends(get_session),
    current_user: User = Depends(get_current_user),
    redmine: RedmineService = Depends(get_redmine_service)
):
    """é è¦½å€é–“å…§çš„è³‡æ–™çµ±è¨ˆ"""
    try:
        start_dt = datetime.strptime(request.start_date, "%Y-%m-%d")
        end_dt = datetime.strptime(request.end_date, "%Y-%m-%d")
    except ValueError:
        raise HTTPException(status_code=400, detail="Invalid date format. Use YYYY-MM-DD")
    
    # å–å¾— Redmine è³‡æ–™
    redmine_data = await fetch_redmine_data(
        redmine, session, current_user, 
        request.start_date, request.end_date
    )
    
    # å–å¾— GitLab è³‡æ–™
    gitlab_data = await fetch_gitlab_data(session, current_user, start_dt, end_dt)
    
    return DataPreviewResponse(
        completed_issues=redmine_data["completed_issues"],
        in_progress_issues=redmine_data["in_progress_issues"],
        gitlab_commits=gitlab_data["commits"],
        gitlab_releases=gitlab_data["releases"],
        available_images=[ImageInfo(**img) for img in redmine_data["images"]]
    )


@router.post("/api/okr-copilot/generate", response_model=GenerateResponse)
async def generate_report(
    request: GenerateRequest,
    session: Session = Depends(get_session),
    current_user: User = Depends(get_current_user),
    redmine: RedmineService = Depends(get_redmine_service),
    openai: OpenAIService = Depends(get_openai_service)
):
    """ç”Ÿæˆå ±å‘Š (å« AI åˆ†æ)"""
    try:
        start_dt = datetime.strptime(request.start_date, "%Y-%m-%d")
        end_dt = datetime.strptime(request.end_date, "%Y-%m-%d")
    except ValueError:
        raise HTTPException(status_code=400, detail="Invalid date format. Use YYYY-MM-DD")
    
    # å–å¾—è³‡æ–™
    redmine_data = await fetch_redmine_data(
        redmine, session, current_user,
        request.start_date, request.end_date
    )
    gitlab_data = await fetch_gitlab_data(session, current_user, start_dt, end_dt)
    
    completed_issues = redmine_data["completed_issues"]
    gitlab_commits = gitlab_data["commits"]
    gitlab_releases = gitlab_data["releases"]
    
    # AI åˆ†æ (Phase 4.1-4.3)
    kr_status = None
    code_summary = None
    next_steps = None
    
    try:
        # 4.1 ç´…ç¶ ç‡ˆåˆ¤æ–·
        kr_status = await analyze_kr_status(
            openai, completed_issues, gitlab_commits, gitlab_releases,
            request.start_date, request.end_date
        )
        
        # 4.2 ä»£ç¢¼è²¢ç»æ‘˜è¦
        code_summary = await generate_code_contribution_summary(
            openai, gitlab_commits, gitlab_releases,
            request.start_date, request.end_date
        )
        
        # 4.3 ä¸‹é€±è¨ˆç•«
        next_steps = await generate_next_steps(
            openai, completed_issues, gitlab_commits, kr_status
        )
    except Exception as e:
        print(f"AI analysis error (non-fatal): {e}")
        # AI åˆ†æå¤±æ•—ä¸å½±éŸ¿å ±å‘Šç”Ÿæˆ
    
    # ç”Ÿæˆ Marp Markdown (å« AI åˆ†æçµæœ)
    markdown = generate_marp_markdown(
        request.start_date,
        request.end_date,
        completed_issues,
        gitlab_commits,
        gitlab_releases,
        request.selected_images,
        kr_status=kr_status,
        code_summary=code_summary,
        next_steps=next_steps,
        completed_issue_list=completed_issues # Pass the list directly as it is already a list of dicts/objects from fetch_redmine_data
    )
    
    # æ§‹å»º AI åˆ†æçµæœ
    ai_analysis = {
        "kr_status": kr_status,
        "code_summary": code_summary,
        "next_steps": next_steps
    } if any([kr_status, code_summary, next_steps]) else None
    
    # å¦‚æœåªéœ€è¦ Markdownï¼Œç›´æ¥è¿”å›
    if request.format == "md":
        return GenerateResponse(markdown=markdown, ai_analysis=ai_analysis)
    
    # å…¶ä»–æ ¼å¼éœ€è¦ä½¿ç”¨ Marp CLI æˆ– Pandoc è½‰æ›
    try:
        # å»ºç«‹æš«å­˜ç›®éŒ„
        temp_dir = tempfile.mkdtemp()
        md_path = os.path.join(temp_dir, "report.md")
        
        # å¯«å…¥ Markdown
        with open(md_path, "w", encoding="utf-8") as f:
            f.write(markdown)
        
        output_path = None
        
        if request.format == "pptx":
            output_path = os.path.join(temp_dir, "report.pptx")
            # ä½¿ç”¨ Marp CLI è½‰æ›
            result = subprocess.run(
                ["npx", "@marp-team/marp-cli", md_path, "--pptx", "-o", output_path],
                capture_output=True,
                text=True,
                timeout=60
            )
            if result.returncode != 0:
                print(f"Marp error: {result.stderr}")
                # å¦‚æœ Marp å¤±æ•—ï¼Œè¿”å› Markdown
                return GenerateResponse(markdown=markdown)
                
        elif request.format == "pdf":
            output_path = os.path.join(temp_dir, "report.pdf")
            result = subprocess.run(
                ["npx", "@marp-team/marp-cli", md_path, "--pdf", "-o", output_path],
                capture_output=True,
                text=True,
                timeout=60
            )
            if result.returncode != 0:
                print(f"Marp error: {result.stderr}")
                return GenerateResponse(markdown=markdown)
                
        elif request.format == "docx":
            output_path = os.path.join(temp_dir, "report.docx")
            # ä½¿ç”¨ Pandoc è½‰æ›
            result = subprocess.run(
                ["pandoc", md_path, "-o", output_path],
                capture_output=True,
                text=True,
                timeout=60
            )
            if result.returncode != 0:
                print(f"Pandoc error: {result.stderr}")
                return GenerateResponse(markdown=markdown)
        
        if output_path and os.path.exists(output_path):
            # è¤‡è£½åˆ°æŒä¹…åŒ–ç›®éŒ„
            output_dir = os.path.join(os.path.dirname(__file__), "..", "..", "temp_files")
            os.makedirs(output_dir, exist_ok=True)
            
            filename = f"okr_report_{current_user.id}_{int(datetime.now().timestamp())}.{request.format}"
            final_path = os.path.join(output_dir, filename)
            shutil.copy(output_path, final_path)
            
            # æ¸…ç†æš«å­˜ç›®éŒ„
            shutil.rmtree(temp_dir, ignore_errors=True)
            
            return GenerateResponse(download_url=f"/api/okr-copilot/download/{filename}")
        
        # æ¸…ç†
        shutil.rmtree(temp_dir, ignore_errors=True)
        
    except subprocess.TimeoutExpired:
        print("Conversion timeout")
    except FileNotFoundError as e:
        print(f"Tool not found: {e}")
    except Exception as e:
        print(f"Conversion error: {e}")
    
    # é è¨­è¿”å› Markdown
    return GenerateResponse(markdown=markdown)


@router.get("/api/okr-copilot/download/{filename}")
async def download_report(
    filename: str,
    current_user: User = Depends(get_current_user)
):
    """ä¸‹è¼‰ç”Ÿæˆçš„å ±å‘Š"""
    output_dir = os.path.join(os.path.dirname(__file__), "..", "..", "temp_files")
    file_path = os.path.join(output_dir, filename)
    
    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail="File not found")
    
    # å®‰å…¨æª¢æŸ¥ï¼šç¢ºä¿æª”æ¡ˆåç¨±åŒ…å«ä½¿ç”¨è€… ID
    if f"_{current_user.id}_" not in filename:
        raise HTTPException(status_code=403, detail="Access denied")
    
    # æ ¹æ“šå‰¯æª”åè¨­å®š content type
    content_types = {
        "pptx": "application/vnd.openxmlformats-officedocument.presentationml.presentation",
        "pdf": "application/pdf",
        "docx": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
        "md": "text/markdown"
    }
    
    ext = filename.split(".")[-1]
    media_type = content_types.get(ext, "application/octet-stream")
    
    return FileResponse(
        file_path,
        media_type=media_type,
        filename=filename
    )
